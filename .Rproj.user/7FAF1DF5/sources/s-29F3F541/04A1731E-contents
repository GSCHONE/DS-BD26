---
title: "R Notebook"
output: html_notebook
author : "Fei GAO"
reference : 'https://r4ds.github.io/bookclub-tmwr/'

---

What is the difference between a Notebook and an R Markdown file?
Markdown is a lightweight markup language for creating formatted text using a plain-text editor.
Markdown est un langage de balisage léger créé en 2004, dans le but d'offrir une syntaxe facile à lire et à écrire. Un document balisé par Markdown peut être converti en HTML, en PDF ou en d'autres formats.


Markdown exists independent of R and is used by a range of techies and alike. A combination of Markdown (which is text with special characters to indicate desired formatting) and R code within it (usually to produce tables and plots) is called R Markdown.
Help menu -> Markdown Quick Reference

Most people use the terms R Notebook and R Markdown interchangeably and that is fine. Technically, R Markdown is a file, whereas R Notebook is a way to work with R Markdown files. R Notebooks do not have their own file format, they all use .Rmd. All R Notebooks can be ‘knitted’ to R Markdown outputs, and all R Markdown documents can be interfaced as a Notebook.  

An important difference is in the execution of code. In R Markdown, when the file is Knit, all the elements (chunks) are also run. Knit is to R Markdown what Source is to an R script (Source was introduced in Chapter 1, essentially it means ‘Run all lines’).  

In a Notebook, when the file is rendered with the Preview button, no code is re-run, only that which has already been run and is present in the document is included in the output. Also, in the Notebook behind-the-scenes file (.nb), all the code is always included. Something to watch out for if your code contains sensitive information, such as a password (which it never should!).  

```{r}
library(tidyverse)
library(tidymodels)
```

Dec 2022, préparation des données 
```{r}
gravity_V2 <- gravity %>% mutate(lum = as.numeric(lum),
                                 sexe = as.numeric(sexe),
                                 agg = as.numeric(agg),
                                 place = as.numeric(place),
                                 trajet = as.numeric(trajet))

getwd()
saveRDS(gravity_V2, 'data/gravity.RDS')
```


```{r}
gravity <- readRDS(file = 'data/gravity.RDS')

gravity <- readRDS(file = 'C:/feigao/Enseignements/R/R_Tidymodel/Tidymodel_dec_22_mise_a_dispo/data/gravity.RDS')

dim(gravity)


glimpse(gravity)
sum(is.na(gravity$grav))




```

### Descriptive Statistics 

- checking missing value in all columns
- tabs and plots

```{r}

apply(is.na(gravity), 2, sum)


colSums(is.na(gravity))

map(gravity, ~sum(is.na(.)))


# sapply(gravity, function(x) sum(is.na(x)))
sapply(gravity, function(x)sum(is.na(x)))


gravity %>%
  # select(everything()) %>%  # replace to your needs
  # summarise_all(funs(sum(is.na(.))))
  summarise_all(list(~sum(is.na(.))))

# Before:
# 
# funs(name = f(.))
# 
# After:
# 
# list(name = ~f(.))


# si on selectionne un echantillon
map(gravity %>% filter(dep ==1), ~sum(is.na(.)))


gravity%>%map(function(x) sum(is.na(x)))

gravity%>%map(~sum(is.na(.)))


1:10 %>%
  map(function(x) rnorm(10, x))

# Or a formula
1:10 %>%
  map(~ rnorm(10, .x))

```


```{r}
library(purrr)

mtcars %>%
  split(.$cyl) %>% # from base R
  map(~ lm(mpg ~ wt, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared")


mtcars %>%
  split(.$cyl) %>% # from base R
  map(~lm(mpg ~ wt, data = .)) %>% map(summary)
```


### Recodage des predictors + data preprocessing part I
```{r}
vars = c('sexe', 'lum', 'agg', 'place', 'trajet')


gravity_tidymodel <- gravity %>% 
  filter(!is.na(grav)) %>% 
  mutate(grav_or_not = as.factor( # classification Y should be a facto
           case_when(
             grav == '2'|grav == '3' ~ '1',
             TRUE ~ '0'
           )
         )) %>% # %>%group_by(grav_or_not, grav)%>%summarise(n = n())
  mutate(secu_or_not = 
           as.numeric(secu1 %in% 1:7 | # as.numeric is necessary here because of xgboost model do not consider T or F as numeric
           secu2 %in% 1:7 |
           secu3 %in% 1:7
           )) %>% #group_by(secu_or_not, secu1, secu2, secu3)%>%summarise(n = n())
  select(-c(grav, secu1, secu2, secu3)) %>% 
  # mutate(across(all_of(vars), as.character))
  mutate_at(all_of(vars), as.factor) # %>% # factor or character ? in our case fact or char there is non importance cause variables are codes. If sex is like male / female, it more interesting to set it as factor
  # mutate_if(is.character, as.factor) %>% # is it necessary 
  # filter(dep %in%c(46, 8, 56, 43, 70, 40, 53, 90, 82, 23))

table(gravity_tidymodel$grav_or_not)

dim(gravity_tidymodel)
gravity$secu1 %in% 1:7
# pas besoin de convertir en caractere

glimpse(gravity_tidymodel)

gravity_tidymodel %>% group_by(dep, grav_or_not) %>% summarise(n=n())%>% 
  pivot_wider(names_from = grav_or_not,
  values_from = n,
  values_fill = 0) %>% 
  mutate(taux = `1`/(`0`+`1`)) %>% arrange(desc(taux))

test$`0`
```

Exemple from Internet
```{r}
data <- head(iris)
contin <- c("Sepal.Length", "Sepal.Width")


data
data %>%
      mutate(across(all_of(contin), ~.x/IQR(.x)))
```



### Definition of training set, validation set and test set
```{r}
set.seed(1234)

gravity_split <- initial_split(gravity_tidymodel, prop = 0.8, strata = grav_or_not) # par defaut prop = 0.75

gravity_train <- training(gravity_split)

gravity_test <- testing(gravity_split)
 
gravity_val_split <- initial_split(gravity_train)

gravity_train_set <- training(gravity_val_split)

gravity_val_set <- testing(gravity_val_split)

```

## Creation of a collection of recipes

### Basic recipe and visualisation of designe matrice

```{r}

# recipe is nothing than a formula
rec_basic <- 
  recipe(grav_or_not~., data = gravity_train_set) 
prep(rec_basic)
juice(prep(rec_basic))


rec_basic <- 
recipe(grav_or_not~., data = gravity_train_set) %>% 
  step_impute_mean(Temperature) %>% 
  # a la page 29 on voit une valeur imputee de temperature
  step_impute_mode(sexe) %>% 
  step_normalize(age) %>% 
  step_other(trajet, threshold = 0.05) %>%
  step_zv(dep) %>% 
  step_dummy(trajet)

prep(rec_basic)
juice(prep(rec_basic)) 


# After imputation
sum(is.na(juice(prep(rec_basic))$Temperature))


juice(prep(rec_basic)) %>% 
  map(is.na) %>% 
  map(sum)

# After step_other
juice(prep(rec_basic)) %>% 
  group_by(trajet) %>% 
  summarise(n = n())

# before step_zv
juice(prep(rec_basic))$dep

# After step_zv
colnames(juice(prep(rec_basic)))


# before it is simply for showing
# final more general version
rec_basic <- 
recipe(grav_or_not~., data = gravity_train) %>% 
  step_impute_mean(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_other(trajet, threshold = 0.05) %>%
  step_zv(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors())

prep(rec_basic)
juice(prep(rec_basic))
dim(juice(prep(rec_basic)))
formula(prep(rec_basic))
```

### Interaction recipe and visualisation of designe matrice

https://bookdown.org/max/FES/detecting-interaction-effects.html

```{r}
rec_interaction <- 
  rec_basic %>% 
  step_interact(~Humidite:Temperature)

rec_interaction <- 
  rec_basic %>% 
  step_interact(~.:.)

rec_interaction <- 
  rec_basic %>% 
  step_interact(~starts_with('lum'):starts_with('traj'))

prep(rec_interaction)
juice(prep(rec_interaction))

```


### Spine recipe and visualisation of designe matrice

```{r}
rec_spline <- 
  rec_interaction %>% 
  step_ns(age, deg_free = 3)
  # step_ns(age, deg_free = tune())

prep(rec_spline)
juice(prep(rec_spline))

```



## Model : https://www.tidymodels.org/find/parsnip/ (mentioned in the diapo)

### RL
```{r}
log_model <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")


log_wflow <- 
  workflow() %>% 
  add_recipe(rec_basic) %>%
  # add_recipe(rec_interaction) %>%
  # add_recipe(rec_spline) %>%
  add_model(log_model)

log_fit <- fit(log_wflow, gravity_train_set)

# Class prediciton for accuracy
predict(log_fit, gravity_val_set)

# proba prediction for AUC
predict(log_fit, gravity_val_set, type = 'prob') # we can do nothing with these results

# concatenate the prediction with the real Y
log_pred <- 
  gravity_val_set %>% 
  select(grav_or_not) %>% 
  bind_cols(predict(log_fit, gravity_val_set), predict(log_fit, gravity_val_set, type = 'prob'))

roc_auc(log_pred, grav_or_not, .pred_0)
accuracy(log_pred, grav_or_not, .pred_class)


# when we take a look of Contingency Table, it is not working
log_pred %>% 
  group_by(grav_or_not, .pred_class) %>% 
  summarise(n=n())

```


### RF : https://medium.com/analytics-vidhya/random-forest-classifier-and-its-hyperparameters-8467bec755f6

Decision trees having low bias and high variance tends to overfit the data. So bagging technique becomes a very good solution for decreasing the variance in a decision tree. 

In general, the more trees in the forest the more robust the forest looks like. In the same way in the random forest classifier, the higher the number of trees in the forest gives the high the accuracy results.

mtry 	=> nb de feuilles, n'est pas implémenter dans tidymodels
A number for the number (or proportion) of predictors that will be randomly sampled at each split when creating the tree models (specific engines only)

trees 	
An integer for the number of trees contained in the ensemble.

min_n => profondeur darbre
An integer for the minimum number of data points in a node that is required for the node to be split further.
= min_sample_split (in python): Parameter that tells the decision tree in a random forest the minimum required number of observations in any given node to split it. Default = 2

```{r}

rf_model <- 
  # rand_forest(trees = 1000) %>%
  rand_forest(trees = tune()) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

rf_workflow <- 
  workflow() %>% 
  add_recipe(recipe = rec_basic) %>%
  add_model(rf_model)

rf_fit <- 
  fit(rf_workflow, gravity_train_set)

predict(rf_fit, gravity_val_set)
predict(rf_fit, gravity_val_set, type = 'prob')

rf_pred <- 
  gravity_val_set %>% 
  select(grav_or_not) %>% 
  bind_cols(predict(rf_fit, gravity_val_set), predict(rf_fit, gravity_val_set, type = 'prob'))
rf_pred

accuracy(rf_pred, grav_or_not, .pred_class)
roc_auc(rf_pred,  grav_or_not, .pred_0)


```

Sans speficier hyperparameters, les hyperparameters par defaut a consulter dans la librarie ranger

### xgboost : General Interface for Boosted Trees

tree_depth 	
An integer for the maximum depth of the tree (i.e. number of splits) (specific engines only).

learn_rate
A number for the rate at which the boosting algorithm adapts from iteration-to-iteration (specific engines only).

loss_reduction 	
A number for the reduction in the loss function required to split further (specific engines only).

sample_size 	
A number for the number (or proportion) of data that is exposed to the fitting routine. For xgboost, the sampling is done at each iteration while C5.0 samples once during training.

stop_iter
The number of iterations without improvement before stopping (specific engines only).

```{r}
xgboost_model <- 
  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), loss_reduction = tune()) %>% 
  # boost_tree() %>% 
  set_engine('xgboost') %>% 
  set_mode('classification')

xgboost_workflow <- 
  workflow() %>% 
  add_recipe(rec_basic) %>% # rec_interaction, rec_spline
  # add_recipe(rec_interaction) %>%
  # add_recipe(rec_spline) %>%
  add_model(xgboost_model)

xgboost_fit <- fit(xgboost_workflow, gravity_train_set)

predict(xgboost_fit, gravity_val_set)
predict(xgboost_fit, gravity_val_set, type = 'prob')

xgboost_pred <- 
  gravity_val_set %>% 
  select(grav_or_not) %>% 
  bind_cols(predict(xgboost_fit, gravity_val_set), predict(xgboost_fit, gravity_val_set, type = 'prob'))
xgboost_pred

accuracy(xgboost_pred, grav_or_not, .pred_class)
roc_auc(xgboost_pred, grav_or_not, .pred_0)

```

## other models
```{r}

svm_p_tune <- 
  svm_poly(degree = tune()) %>% # cost = tune()
  set_engine('kernlab') %>% 
  set_mode("classification")

knn_tune <- 
  nearest_neighbor(neighbors = tune()) %>%  # dist_power = tune(), weight_func = tune()
  set_engine('kknn') %>% 
  set_mode("classification")

nnet_tune <- 
  mlp(penalty = tune(), epochs = tune()) %>% # hidden_units = tune() The number of hidden neurons
  set_engine('nnet') %>% 
  set_mode('classification')

```



## Create a collection of workflows
1. show without label then with label
```{r}

# for showing
workflow_set(
  preproc = list(
    rec_basic,
    rec_interaction,
    rec_spline
    
  ), # a list of recipes
  
  models= list(
    log_model,
    rf_model,
    xgboost_model
  ) # a list of models
  
)


chi_models <- workflow_set(
  preproc = list(
    basic = rec_basic,
    inter = rec_interaction,
    spline = rec_spline
    
  ), # a list of recipes
  
  models= list(
    #log =log_model,
    rf =rf_model
    # xgboost= xgboost_model
    # svm_p = svm_p_tune,
    # knn = knn_tune,
    # nnet = nnet_tune
  ) # a list of models
  
)

chi_models
```

**Grid search**
tune_grid() is the primary function for conducting grid search. It resembles fit_resamples() from prior chapters, but adds

grid: An integer or data frame. When an integer is used, the function creates a space-filling design. If specific parameter combinations exist, the grid parameter is used to pass them to the function.

param_info: An optional argument for defining the parameter ranges, when grid is an integer.


**tune_bayes()**
The tune_bayes() function sets up Bayesian optimization iterative search. It’s similar to tune_grid() but with additional arguments. You can specify the maximum number of search iterations, the acquisition function to be used, and whether to stop the search if no improvement is detected. See Max and Julia for details and additional arguments.

test for tune_bayes
```{r}
gravity_resample <- vfold_cv(gravity_train_set, v = 3)



ctrl_bayes = control_bayes(save_pred = TRUE,
                           parallel_over = "everything",
                           save_workflow = TRUE)

bayes_results <-
  chi_models %>%
  workflow_map(
    seed = 1,
    fn = "tune_bayes",
    resamples = gravity_resample,
    initial = 10, # le pb est probablement ici : 1 hyperparametre a tuner, une valeur initial, 
    control = ctrl_bayes
  )

bayes_results
```

https://finetune.tidymodels.org/
**The tune_sim_anneal() function**
```{r}

ctrl_sa <- control_sim_anneal(verbose = TRUE, no_improve = 10L)

set.seed(1234)

svm_sa <-
  svm_wflow %>%
  tune_sim_anneal(
    resamples = penguins_folds,
    metrics = roc_res,
    initial = svm_initial,
    param_info = svm_param,
    iter = 50,
    control = ctrl_sa
  )

svm_sa <-
  chi_models %>%
  workflow_map(
    seed = 1,
    fn = finetune::tune_sim_anneal,
    metrics = roc_res,
    resamples = gravity_resample,
    initial = 10, # le pb est probablement ici : 1 hyperparametre a tuner, une valeur initial, 
    iter = 5,
    control = ctrl_bayes
  )

```

Warning: All models failed. See the `.notes` column.
Run `rlang::last_error()`



## fitting
```{r}
gravity_resample <- vfold_cv(gravity_train_set, v = 3)

# result view gestion
keep_pred <- control_resamples(save_pred = T, save_workflow = T)

chi_models <- chi_models %>% 
  workflow_map(
    resamples = gravity_resample,
    grid = 20,
    metrics = metric_set(accuracy, roc_auc, sensitivity, specificity, f_meas),
    control=keep_pred,
    verbose = T
  )

```

## Evaluation des models
```{r}
bayes_results
rank_results(chi_models, rank_metric = 'f_meas')

rank_results(bayes_results, rank_metric = 'roc_auc')

autoplot(chi_models, metric = "roc_auc", , std_errs = qnorm(0.95))

autoplot(chi_models, metric = "roc_auc", , std_errs = qnorm(0.9))

autoplot(chi_models, metric = "accuracy", , std_errs = qnorm(0.9))


rank_results(chi_models, rank_metric = 'roc_auc') %>% 
  filter(wflow_id == 'spline_xgboost') %>% 
  group_by(.config) %>% 
  summarise(n=n())

# 0.6558810 ROC
# 
```

### select the best workflow and see the best hyperparameter tuning results
```{r}

best_result <- 
  chi_models %>% 
  extract_workflow_set_result('basic_xgboost') %>% 
  select_best(metric = 'specificity')
  
best_result

```

## last fitting
```{r}

best_result_fit <- 
  chi_models %>% 
  extract_workflow('basic_xgboost') %>% # in my opinion here we should improuve the coding manner
  finalize_workflow(best_result) %>% 
  last_fit(split = gravity_split) # notice that here we learn from all dataset


best_result_fit %>% collect_predictions() 

best_result_fit %>% collect_metrics()


best_result_fit %>% collect_predictions() %>% group_by(grav_or_not, .pred_class) %>% summarise(n = n()) 

```

